<!DOCTYPE html>


  
<html itemscope itemtype="https://schema.org/WebPage" class="no-js" lang="en">

<head prefix="og: http://ogp.me/ns#"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="siteBaseUrl" content="http://localhost:1313/">
    <meta name="author" content="eosfor">
    <meta name="description" content="My thoughts around modern IT">
    <meta name="keywords" content="">
    <meta name="generator" content="Hugo 0.145.0">
    <title>
        
           
               Adventures in Agentic AI Simulation Land &vert; Modern IT Engineer
           
        
    </title>
    <meta itemprop="name" content="Adventures in Agentic AI Simulation Land">
    <meta itemprop="description" content="Adventures in Agentic AI Simulation Land - My thoughts around modern IT">
    <meta property="og:site_name" content="Modern IT Engineer">

    <meta property="og:url" content="http://localhost:1313/article/agentic-ai-infra-sim/agentic-ai-infra-sim/">
  <meta property="og:site_name" content="Modern IT Engineer">
  <meta property="og:title" content="Adventures in Agentic AI Simulation Land">
  <meta property="og:description" content="(Or, How We Learned to Stop Worrying and Love the Cloud)
Have you ever wondered how a cloud-based, multi-agent AI service handles a flurry of incoming user requests without spontaneously combusting? Well, wonder no more! In this blog post, we’ll embark on a fun, light-hearted journey through a simulation that tests just how gracefully an AI agentic system (think: a set of AI agents working together) scales, splits, and handles all sorts of query traffic. We’ll talk about our framework, assumptions, code, and results—complete with a snazzy chart to show off our data.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="article">
    <meta property="article:published_time" content="2025-03-11T01:25:25-07:00">
    <meta property="article:modified_time" content="2025-03-11T01:25:25-07:00">


    


    <script src="/modernizr-simple.js"></script>

    


    
    <link rel="canonical" href="http://localhost:1313/article/agentic-ai-infra-sim/agentic-ai-infra-sim/">
    

    <link rel="stylesheet" href="http://localhost:1313/theme.css">

    

    

    
</head>

<body class="bilberry-hugo-theme">
    

    
    <nav>

    <div class="container">
        <ul class="topnav">
            
        </ul>

        
    </div>
</nav>


    
    <header>

    <div class="container">
        <div class="logo">
            <a href="/" class="logo">
                
                    <img src="/img/avatar.jpg" alt="">
                

                <span class="overlay"><i class="fa fa-home"></i></span>
            </a>
        </div>
        <div class="titles">
            <h3 class="title">
                <a href="/">
                    Modern IT Engineer
                </a>
            </h3>

            
        </div>

        <div class="languages">
            
                
                
                  
                

                
                    <a href="/article/agentic-ai-infra-sim/agentic-ai-infra-sim/" class="active">en</a>
                
            
                
                

                
                    <a href="/ru/">ru</a>
                
            
            </div>
        

        
            <div class="toggler">
        
                <i class="fa fa-bars" aria-hidden="true"></i>
            </div>
    </div>
</header>


    <div class="main container">
        
    <div class="article-wrapper u-cf single">
        
            <a class="bubble" href="http://localhost:1313/article/agentic-ai-infra-sim/agentic-ai-infra-sim/">
    <i class="fas fa-fw fa-pencil-alt"></i>
</a>

<article class="default article">
    

    <div class="content">
    <h1 class="article-title">
        <a href="http://localhost:1313/article/agentic-ai-infra-sim/agentic-ai-infra-sim/">
            Adventures in Agentic AI Simulation Land
        </a>
    </h1>

    <div class="meta">
        
            
                <span class="date moment">2025-03-11</span>
            
        

        

        

        
    </div>

    
        

        <p>(Or, How We Learned to Stop Worrying and Love the Cloud)</p>
<p>Have you ever wondered how a cloud-based, multi-agent AI service handles a flurry of incoming user requests without spontaneously combusting? Well, wonder no more! In this blog post, we’ll embark on a fun, light-hearted journey through a simulation that tests just how gracefully an AI agentic system (think: a set of AI agents working together) scales, splits, and handles all sorts of query traffic. We’ll talk about our framework, assumptions, code, and results—complete with a snazzy chart to show off our data.</p>
<ol>
<li>The Task at Hand</li>
</ol>
<p>Imagine you’re running a magical multi-agent AI system in the cloud. Users keep sending in queries, each one with a certain number of tokens, and your AI agents must figure out how to handle them. Sometimes they split requests, sometimes they drop them if they’re too big, and sometimes they direct them right through the main pipeline. We want to figure out:
•	How many requests do we get in total?
•	How many do we split vs. send directly?
•	How often do we drop requests (and at what cost)?
•	How does all of this affect our resource usage and total cost (in good old dollars)?</p>
<p>In other words, we want to simulate the day-to-day life of our AI agentic system and see what happens when the going gets tough—or at least, when the queries keep rolling in.</p>
<ol start="2">
<li>Our Simulation Framework</li>
</ol>
<p>For our simulation, we put on our Python hats and set up a playful environment. We used libraries like numpy, pandas, and possibly tqdm for those delightful progress bars that let us watch our simulation run in real time. Our main steps looked a bit like this:
1.	Generate incoming requests: We produce a batch of user queries with random sizes (in tokens).
2.	Route the requests: Some requests go directly to the AI agents; others are split into multiple smaller requests if they’re too large.
3.	Cost modeling: We keep track of how many tokens each request uses, then calculate LLM (or multi-agent) costs and AKS (Azure Kubernetes Service) costs based on usage—both in dollars.
4.	Statistics: We record everything—number of direct requests, split requests, dropped requests, total tokens, and costs.
5.	Repeat: We run this entire simulation multiple times (100 runs, in our case) to get nice summary statistics.</p>
<p>This framework gives us a robust way to see how our hypothetical cloud-based AI system behaves under a variety of random conditions.</p>
<ol start="3">
<li>Assumptions &amp; Numbers</li>
</ol>
<p>Now for the fun part—how did we decide which numbers to plug in?
•	Token Distribution: We assumed user queries come in a variety of sizes, with a certain average length and standard deviation. The system (i.e., our band of AI agents) might add some overhead tokens for each query because, hey, systems gotta system.
•	Split Threshold: If a query exceeded our threshold, we split it into smaller pieces. We set this threshold somewhat arbitrarily based on what we thought was a “typical big request.”
•	Costs in Dollars: We used a made-up cost model for LLM usage and AKS usage. For example, maybe 1 million tokens cost a certain number of dollars, and each AKS node has a cost per hour. We aimed to keep these costs in a plausible range for demonstration purposes.
•	Dropping Requests: We allowed the system to drop requests if they were too huge or if the cluster was at capacity. We pretended it was more cost-effective to drop them than to scale to infinity—harsh, but it’s just a simulation!</p>
<p>Our goal was not to create a perfectly realistic production environment, but rather to highlight the trade-offs and behaviors that might emerge under these assumptions.</p>
<ol start="4">
<li>A Quick Peek at the Code</li>
</ol>
<p>We won’t overwhelm you with all the gritty details, but here’s the general shape of our Python code:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> trange
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NUM_RUNS <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> run <span style="color:#f92672">in</span> trange(NUM_RUNS):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 1. Generate requests</span>
</span></span><span style="display:flex;"><span>    user_queries <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>poisson(lam<span style="color:#f92672">=</span><span style="color:#ae81ff">5000</span>, size<span style="color:#f92672">=</span>some_size)  <span style="color:#75715e"># Just an example</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 2. Route requests</span>
</span></span><span style="display:flex;"><span>    direct_requests <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    split_requests <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    dropped_requests <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    total_tokens <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ... Some logic for splitting or dropping requests ...</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 3. Track costs (in dollars)</span>
</span></span><span style="display:flex;"><span>    llm_cost <span style="color:#f92672">=</span> <span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span>    aks_cost <span style="color:#f92672">=</span> <span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span>    total_cost <span style="color:#f92672">=</span> llm_cost <span style="color:#f92672">+</span> aks_cost
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 4. Append results for each run</span>
</span></span><span style="display:flex;"><span>    results<span style="color:#f92672">.</span>append({
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;direct_requests&#39;</span>: direct_requests,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;split_requests&#39;</span>: split_requests,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;dropped_requests&#39;</span>: dropped_requests,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;total_requests&#39;</span>: direct_requests <span style="color:#f92672">+</span> split_requests,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;llm_cost&#39;</span>: llm_cost,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;aks_cost&#39;</span>: aks_cost,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;total_cost&#39;</span>: total_cost,
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># ... other stats ...</span>
</span></span><span style="display:flex;"><span>    })
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert results to a DataFrame and compute summary statistics</span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(results)
</span></span><span style="display:flex;"><span>summary <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>describe()
</span></span><span style="display:flex;"><span>print(summary)
</span></span></code></pre></div><p>Essentially:
1.	We generate a batch of requests with random sizes.
2.	We decide whether to direct them, split them, or drop them.
3.	We calculate how many tokens went through and the costs in dollars.
4.	We collect all these stats in a DataFrame and spit out summary statistics.</p>
<ol start="5">
<li>Results: The Grand Reveal</li>
</ol>
<p>After 100 simulation runs, we got some neat summary statistics:</p>
<table>
  <thead>
      <tr>
          <th>Metric</th>
          <th>mean</th>
          <th>std</th>
          <th>min</th>
          <th>max</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>direct_requests</td>
          <td>6479</td>
          <td>85.76</td>
          <td>6279</td>
          <td>6641</td>
      </tr>
      <tr>
          <td>split_requests</td>
          <td>25931</td>
          <td>157</td>
          <td>25462</td>
          <td>26347</td>
      </tr>
      <tr>
          <td>dropped_requests</td>
          <td>591</td>
          <td>38.74</td>
          <td>506</td>
          <td>696</td>
      </tr>
      <tr>
          <td>total_requests</td>
          <td>32410</td>
          <td>182</td>
          <td>31945</td>
          <td>32823</td>
      </tr>
      <tr>
          <td>percent_split</td>
          <td>80.01</td>
          <td>0.23</td>
          <td>79.46</td>
          <td>80.60</td>
      </tr>
      <tr>
          <td>user_query_tokens</td>
          <td>3561909</td>
          <td>53503</td>
          <td>3445529</td>
          <td>3669273</td>
      </tr>
      <tr>
          <td>system_query_tokens</td>
          <td>95085770</td>
          <td>517611</td>
          <td>93430542</td>
          <td>96296984</td>
      </tr>
      <tr>
          <td>llm_response_tokens</td>
          <td>42782889</td>
          <td>225980</td>
          <td>42077728</td>
          <td>43267966</td>
      </tr>
      <tr>
          <td>total_llm_tokens</td>
          <td>141430570</td>
          <td>743063</td>
          <td>139073264</td>
          <td>143077558</td>
      </tr>
      <tr>
          <td>llm_cost (USD)</td>
          <td>424</td>
          <td>2.23</td>
          <td>417</td>
          <td>429</td>
      </tr>
      <tr>
          <td>aks_cost (USD)</td>
          <td>858</td>
          <td>2.32</td>
          <td>852</td>
          <td>864</td>
      </tr>
      <tr>
          <td>total_cost (USD)</td>
          <td>1283</td>
          <td>4.35</td>
          <td>1269</td>
          <td>1293</td>
      </tr>
      <tr>
          <td>max_nodes</td>
          <td>11.00</td>
          <td>0.00</td>
          <td>11.00</td>
          <td>11.00</td>
      </tr>
      <tr>
          <td>avg_nodes</td>
          <td>8.01</td>
          <td>0.02</td>
          <td>7.95</td>
          <td>8.07</td>
      </tr>
  </tbody>
</table>
<p>What does all this mean?</p>
<ul>
<li>We’re seeing around 80% of requests get split. That means our threshold is set so that a good chunk of queries are big enough to be chopped into smaller pieces.</li>
<li>We drop a relatively small number of requests (591 on average), which might be acceptable if we’re optimizing for cost rather than 100% coverage.</li>
<li>The total cost in dollars ends up around $1283, with LLM cost at about $424 and AKS cost at about $858. Looks like our AI usage is cheaper than our compute infrastructure in this scenario!</li>
<li>Max nodes at 11 suggests we capped our cluster at 11 nodes. On average, we only used about 8 nodes, which means we have a bit of headroom before we start dropping too many requests.</li>
</ul>
<p>And here’s the visual side of things (see the attached figure). It shows:</p>
<ul>
<li>Normalized Avg AKS Nodes: The resource usage over time.</li>
<li>Normalized Avg Incoming Requests: The load the system faces.</li>
<li>Normalized Avg Failed Requests: Times when requests might be dropped.</li>
<li>PCA Correlation Curve: A fancy way to see which metrics move together over time. If this curve spikes, it means certain variables (like incoming requests and node usage) are highly correlated.</li>
</ul>
<p>From the chart, we can see that whenever the load spikes (green line), the AKS nodes usage (blue line) tends to respond. The failed requests (orange line) stay relatively low, indicating our scaling strategy handles most spikes well. The PCA correlation curve (gray dotted line) helps confirm which periods show the strongest relationships among these metrics.</p>
<p><img src="chart.jpeg" alt="chart"></p>
<p>Wrapping Up (and a Question for You!)</p>
<p>That’s it, folks! Our little simulation shows how a cloud-based agentic AI system might behave under varying loads, token sizes, and cost constraints. We made some assumptions about how queries are split, what gets dropped, and how costs scale—but in reality, you’d tweak these parameters to match your production environment.</p>
<p>Question for you: If you’re running a similar system of AI agents, do your numbers correlate with ours? Maybe you see a different ratio of split vs. direct requests, or maybe your costs behave differently. Let us know how our model compares to your real-world experiences!</p>
<p>We hope this gave you a fun peek into the world of AI simulation and resource planning. If you’re ever curious about whether your next big idea might break the bank (or break your cluster), a quick simulation like this can give you some peace of mind—or at least a direction for more fine-grained modeling!</p>
<p>Thanks for joining us on this cloud-surfing, token-crunching, agent-wrangling adventure. Until next time, happy simulating!</p>
    
</div>

    
<div class="footer no-tags">


    

    
</div>

</article>

        
    </div>

    
        <div id="comments-container">
            
            

            

            

        </div>
    
    

    </div>

    
<footer>
    <div class="container">

        
        <div class="recent-posts">
            <strong>Latest posts</strong>
            <ul>
                
                
                    <li>
                        <a href="http://localhost:1313/article/agentic-ai-infra-sim/agentic-ai-infra-sim/">Adventures in Agentic AI Simulation Land</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/sankey-d3/">Visualizing Traffic Flow through Azure Firewall Using PowerShell, Jupyter, and d3js</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/azure-networking-d3js/">Visualizing Azure Networking using D3js</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/how-to-deal-with-zscaler-and-azcli/">How to Make ZScaler and Azure CLI Work Together</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/more-notebooks-ps/">Continuing the Conversation on Jupyter and PowerShell</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/no-caf-webapps/">Do we always need to follow CAF recommendations?</a>
                    </li>
                
                    <li>
                        <a href="http://localhost:1313/article/aproach-to-optimizing-vm-costs/">Approach to Optimizing VM Costs</a>
                    </li>
                
            </ul>
        </div>
        

        
        <div class="categories">
            
            <a href="http://localhost:1313/categories/"><strong>Categories</strong></a>
            

            <ul>
                
                <li>
                
                    <a href="http://localhost:1313/categories/powershell/">PowerShell (2)</a>
                
                </li>
                
                <li>
                
                    <a href="http://localhost:1313/categories/azure/">Azure (1)</a>
                
                </li>
                
                <li>
                
                    <a href="http://localhost:1313/categories/kubernetes/">Kubernetes (1)</a>
                
                </li>
                
                <li>
                
                    <a href="http://localhost:1313/categories/psquickgraph/">PSQuickGraph (1)</a>
                
                </li>
                
            </ul>
        </div>
        

        <div class="right">
            
            <div class="external-profiles">
                <strong>Social media</strong>
                
            </div>
            

            <div class="languages">
                    <strong>Other languages</strong>
                    
                        
                        
                            
                        

                        
                            <a href="/article/agentic-ai-infra-sim/agentic-ai-infra-sim/" class="active">en</a>
                        
                    
                        
                        

                        
                            <a href="/ru/">ru</a>
                        
                    
                </div>
            

            
            <div class="archive">
                
            </div>
            
        </div>
    </div>
</footer>


<div class="credits">
    <div class="container">
        <div class="copyright">
            <a href="https://github.com/Lednerb" target="_blank">
                &copy;
                
                2018 - 2025
                
                by Lednerb
            </a>
            
        </div>
        <div class="author">
            <a href="https://github.com/Lednerb/bilberry-hugo-theme"
                target="_blank">Bilberry Hugo Theme</a>
        </div>
    </div>
</div>


    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-4SWGXNDCQX"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-4SWGXNDCQX');
        }
      </script>

    
    <script src="http://localhost:1313/theme.js"></script>
    

    

    

    
</body>

</html>
